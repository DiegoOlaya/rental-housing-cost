{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the News API to find articles related to rent from different years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '3d0b3cf27776446c885f1e8ca8356c8c'\n",
    "endpoint = 'https://newsapi.org/v2/everything'\n",
    "\n",
    "def set_query(search_str, sources=None):\n",
    "    query_params = {\n",
    "        'apiKey': API_KEY,\n",
    "        'q': search_str,\n",
    "        'language': 'en',\n",
    "        'order': 'relevancy',\n",
    "    }\n",
    "    if sources:\n",
    "        query_params['sources'] = sources\n",
    "    return query_params\n",
    "\n",
    "def get_articles(search_str, sources=None) -> pd.DataFrame:\n",
    "    resp = requests.get(endpoint, params=set_query(search_str, sources))\n",
    "    resp_json = resp.json()\n",
    "    #return resp_json # For debugging\n",
    "    if resp_json['status'] == 'error':\n",
    "        print(f\"Error: {resp_json['message']}\")\n",
    "        return None\n",
    "    df = pd.json_normalize(resp.json()['articles'])\n",
    "    return df\n",
    "\n",
    "def clean_text(text:str):\n",
    "    text=re.sub(r'[,.;@#?!&$\\-]+', ' ', text, flags=re.IGNORECASE)\n",
    "    text=re.sub(' +', ' ', text, flags=re.IGNORECASE)\n",
    "    text=re.sub(r'\\\"', ' ', text, flags=re.IGNORECASE)\n",
    "    text=text.replace(\"'\", '')\n",
    "    text=re.sub(r'[^a-zA-Z]', \" \", text, flags=re.VERBOSE)\n",
    "    # Remove commas from the file.\n",
    "    text=text.replace(',', '')\n",
    "    text=' '.join(text.split())\n",
    "    # Remove carriage returns and new lines.\n",
    "    text=re.sub(\"\\n|\\r\", \"\", text)\n",
    "    ### AS AN OPTION - remove words of a given length............\n",
    "    stop_words = ['the', 'are', 'and', 'for', 'our', 'but', 'that', 'you', 'your', 'like', 'with', 'was',\n",
    "                  'can', 'when', 'has', 'not', 'this', 'who', 'what', 'when', 'their', 'they', 'them', 'one', 'she', 'her',\n",
    "                  'could', 'from', 'his', 'him', 'he']\n",
    "    text = ' '.join([wd.lower() for wd in text.split() if (len(wd)>2 and (wd.lower() not in stop_words))])\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NewsAPI plan cannot search articles far back in the past. So we'll search the articles we do have access too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_articles = get_articles(\n",
    "    '(\"cost of living\" OR \"housing cost\" OR rent) -vacation -car -movie -streaming -moved'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96 entries, 0 to 95\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   author       84 non-null     object\n",
      " 1   title        96 non-null     object\n",
      " 2   description  92 non-null     object\n",
      " 3   url          96 non-null     object\n",
      " 4   urlToImage   91 non-null     object\n",
      " 5   publishedAt  96 non-null     object\n",
      " 6   content      96 non-null     object\n",
      " 7   source.id    33 non-null     object\n",
      " 8   source.name  96 non-null     object\n",
      "dtypes: object(9)\n",
      "memory usage: 6.9+ KB\n"
     ]
    }
   ],
   "source": [
    "rent_articles.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 97 articles to go through. We will clean and isolate the description of the articles for ARM. This reduces the number of articles to 93."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = [clean_text(title) for title in rent_articles['title']]\n",
    "article_desc = [clean_text(content) for content in rent_articles[~rent_articles['description'].isna()]['description']]\n",
    "articles = [title + ' ' + desc for title, desc in zip(article_titles, article_desc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the words up into arrays and then save as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_mat = [line.split() for line in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/rent_articles.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for line in words_mat:\n",
    "        writer.writerow(line)\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".rent_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
